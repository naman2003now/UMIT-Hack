# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ajtDhSLlUDkR4o47QzrmrsitIm9gDaaS
"""

import numpy as np 
import pandas as pd

df = pd.read_json('IIT5.json')
'''
df2 = pd.read_csv('databaseNit.csv')
df3 = pd.read_csv('database1.csv')
df4 = pd.read_csv('packages.csv')
'''

df.head()

dft = df.transpose()

dft.head()

dft['Computer Science and Engineering'].apply(pd.Series)

df2 = pd.json_normalize(df['IIT-Jammu'])

df2['Uni'] = 'IIT-Jammu'

df2 = df2.set_index('Uni')

df2.head()

dft.head()

dft.loc['IIT-Dharwad']['Computer Science and Engineering']['Cutoffs']['2021']['Round-1']['GEN Gender-Neutral']

km = []
clgs = []
kmd = []

for i in df.columns:
  for j in dft.columns:
    if(type(dft.loc[i][j]) is dict):
      for k in dft.loc[i][j]:
        if(k == 'Cutoffs'):
          print('i=',i,'j=',j,'k=',k,'val=',dft.loc[i][j][k]['2021']['Round-1']['GEN Gender-Neutral'])
          a1 = int(dft.loc[i][j][k]['2021']['Round-1']['GEN Gender-Neutral']['Opening'])
          a2 = int(dft.loc[i][j][k]['2021']['Round-1']['GEN Gender-Neutral']['Closing'])
          km.append([a1,a2])
          clgs.append(i + ' ' + j)
          kmd.append([i,j,k,'2021','Round-1','GEN Gender-Neutral'])
  print()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

km2 = np.array(km).astype(np.float)
km2

plt.scatter(km2[:,0], km2[:,1])
plt.xlim([0,5000])
plt.ylim([0,5000])

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters = 5)

kmeans.fit(km2)

#fig, (ax1,ax2) = plt.subplots(1,2,sharey=True,figsize=(10,6))
plt.scatter(km2[:,0],km2[:,1],c=kmeans.labels_,cmap='rainbow',s=3)

#ax2.scatter(km2[:,0],km2[:,1],c=kmeans.labels_,cmap='rainbow')

plt.xlim([0,15000])
plt.ylim([0,15000])

kmeans.predict([[1,1]])[0]

kmeans.labels_





import sklearn
from sklearn.decomposition import TruncatedSVD

#from pandas_profiling import ProfileReport

userId = [str(i) for i in range(1000)]
mat = pd.DataFrame(index = userId, columns = clgs)

mat = mat.fillna(0)
mat

from random import choices
#prior
p = [4,5]
w = [0.40,0.60]

#2nd
pe = [1,2]
we = [0.30,0.70]

lp = []
wsc = {}
best = ['Madras', 'Delhi', 'Bombay', 'Kharagpur', 'Kanpur', 'Roorkee']
streams = ['Computer Science', 'Mechanical', 'Electrical', 'Electronics', 'Civil', 'Chemical']
best = ['IIT-'+i for i in best]
#print(best)
fl1 = []
ind = 0

for q in range(20):
  lp = []
  
  for z in streams:    
    for y in streams:
      if (y == z):
        continue      
      wsc[(z,y)] = ind      
      ind += 1
      lp = []
      for i in clgs:
        if z in i:
          #print(i, choices(p, w))
          found = 0
          for j in best: #if in top iit
            if j in i:
              found = 1
              #print('hey')
              lp.append(5)        
              break
          if not found:
            lp.append(choices(p, w)[0])

        elif y in i:
          #print(i, choices(pe,we))
          lp.append(choices(pe,we)[0])
        else:
          lp.append(0)
      fl1.append(lp)

wsc

len(fl1)

#mat.iloc[0:50] = [lp for i in range(50)]
#[lp for i in range(50)]
mat.iloc[0:600] = fl1
mat.head()

'''
lp2 = []
for i in clgs:
  if 'Computer' in i:
    print(i, choices(pe, we))
    lp2.append(choices(pe, we)[0])
  elif 'Electronics' in i:
    print(i, choices(p,w))
    found = 0
    for j in best:
      if j in i:
        found = 1
        print('hey')
        lp2.append(5)        
        break
    if found == 0:
      lp2.append(choices(p, w)[0])
  else:
    lp2.append(0)
  '''

'''
mat.iloc[50:100] = lp2
mat.iloc[50:60]
'''

#mat2 = mat.pivot_table()

#pf = ProfileReport(mat)
#pf

mtt = mat.T
mtt.head()

SVD = TruncatedSVD(n_components=10)
decomposed_matrix = SVD.fit_transform(mat)
decomposed_matrix.shape

SVD2 = TruncatedSVD(n_components=10)
decomposed_matrix2 = SVD2.fit_transform(mtt)
decomposed_matrix2.shape

decomposed_matrix

df=pd.DataFrame(decomposed_matrix)
df2=pd.DataFrame(decomposed_matrix2)

correlation_matrix = np.corrcoef(decomposed_matrix)
correlation_matrix.shape

correlation_matrix2 = np.corrcoef(decomposed_matrix2)

df.head()

mtt.index[0]

product_names = list(mat.index)
product_names[:10]

product_names2 = list(mtt.index)

import pickle

#inputs 

lrank = 1
hrank = 2
stream1 = 'Computer Science'
stream2 = 'Electrical'

class Model:
  global mat
  i = '0'
  lrank = 1
  hrank = 2
  r_names = None
  r_ID = None
  corr_ID = None
  recc = None
  cmat = mat


m1 = Model()
print(m1.i)
m1.i = wsc[(stream1, stream2)]
m1.lrank = lrank
m1.hrank = hrank
print(m1.cmat)

#from google.colab import drive
#drive.mount('/content/gdrive')

filename = 'Model1.pckl'
filename2 = 'table.pckl'
pickle.dump(m1, open(filename, 'wb'))
pickle.dump(mat, open(filename2, 'wb'))

#i2 = "IIT-Roorkee Electronics and Communication Engineering"
i2 = 'IIT-Roorkee Computer Science and Engineering'
i = '0'

product_names = list(mat.index)
product_ID = product_names.index(i)
product_ID

product_names2 = list(mtt.index)
product_ID2 = product_names2.index(i2)

correlation_product_ID = correlation_matrix[product_ID]
correlation_product_ID[:50]

correlation_product_ID2 = correlation_matrix2[product_ID2]

#mtt2 = mtt.sort_index(level = correlation_product_ID, ascending=False)
Recommend = list(mat.index[correlation_product_ID > 0.70])
#Recommend

Recommend2 = list(mtt.index[correlation_product_ID2 > 0.70])
Recommend2

#for i in mat.loc['120'].items():
#  print(i[0], i[1])

fl = []
for i in range(len(correlation_product_ID)):
  if(correlation_product_ID[i] > 0.50):
    fl.append([correlation_product_ID[i], mat.index[i]])
fl.sort(reverse=True)
flf = []
for i in range(len(fl)):
  if (fl[i][0] > 0.95):
    flf.append(fl[i])
flf

fl2 = []
for i in range(len(correlation_product_ID2)):
  if(correlation_product_ID2[i] > 0.50):
    
    fl2.append([correlation_product_ID2[i], mtt.index[i]])
fl2.sort(reverse=True)
fl2

